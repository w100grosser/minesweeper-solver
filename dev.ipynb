{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '/path/to/chromedriver' with the actual path to the chromedriver executable\n",
    "driver = webdriver.Chrome('chromedriver')\n",
    "url = 'https://minesweeperonline.com/'  # Replace with the URL of the webpage you want to extract HTML from\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Minesweeper():\n",
    "    def __init__(self, driver):\n",
    "        self.driver = driver\n",
    "        self.reset()\n",
    "        self.cell_state = np.zeros((16,30,10), dtype=np.int8)\n",
    "        self.update()\n",
    "        \n",
    "        self.end = 0\n",
    "        self.win = 0\n",
    "        self.lose = 0\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def update_action(self, action):\n",
    "        reward = 0\n",
    "        self.action = np.reshape(action, (16,30))\n",
    "        cell_ij = np.unravel_index(np.argmax(self.action), self.action.shape)\n",
    "        # print(cell_ij)\n",
    "        # Find the element by ID\n",
    "\n",
    "        element = self.driver.find_element_by_id(f\"{cell_ij[0] + 1}_{cell_ij[1] + 1}\")  # Replace \"element_id\" with the actual ID of your element\n",
    "\n",
    "        # Click on the element\n",
    "        element.click()\n",
    "        self.update()\n",
    "\n",
    "        if self.end:\n",
    "            if self.win:\n",
    "                reward = 100\n",
    "            else:\n",
    "                reward = -10\n",
    "        else:\n",
    "            reward = 1\n",
    "        return self.cell_state[:,:,:], reward, self.end, self.win, self.lose\n",
    "    \n",
    "    \n",
    "    def update(self):\n",
    "        html_content = self.driver.page_source\n",
    "        self.soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        self.game = self.soup.find(\"html\").find(\"body\").find(\"table\").find(\"tbody\").find(\"tr\").find(\"td\").find(\"div\").find(\"div\", id=\"center-column\").find('div', id= \"game-container\").find('div', id = 'game')\n",
    "        self.game1 = self.game.find_all(class_=\"square\")\n",
    "        self.end = 0 if self.game.find(\"div\", class_=\"facesmile\") else 1\n",
    "        self.win = 1 if self.game.find(\"div\", class_=\"facewin\") else 0\n",
    "        self.lose = 1 if self.game.find(\"div\", class_=\"facedead\") else 0\n",
    "        self.cell_state[:,:,:] = 0\n",
    "        time0 = time.time()\n",
    "        for i in range(1, 17):\n",
    "            for j in range(1, 31):\n",
    "                state = self.game1[(i - 1) * 30+j - 1][\"class\"][-1]\n",
    "                match state:\n",
    "                    case \"blank\":\n",
    "                        # print(f\"block {i} {j}: is blank\")\n",
    "                        self.cell_state[i-1,j-1,0] = 1\n",
    "                        # Perform actions specific to case 1\n",
    "                    case value if value.startswith(\"open\"):\n",
    "                        # print(f\"block {i} {j}: is open {value[-1]}\")\n",
    "                        self.cell_state[i-1,j-1, int(value[-1])] = 1\n",
    "                        # Perform actions specific to case 2\n",
    "                    case value if value.startswith(\"bombflagged\"):\n",
    "                        # print(f\"block {i} {j}: is bombflagged\")\n",
    "                        self.cell_state[i-1,j-1,9] = 1\n",
    "                        # Perform actions specific to case 3\n",
    "                    case _:\n",
    "                        # print(f\"Invalid case for block {i} {j}: {state}\")\n",
    "                        return 1\n",
    "                        # Handle an invalid or unexpected case\n",
    "        # /html/body/table/tbody/tr/td/div/div[2]/div[1]/div[2]/div[1]\n",
    "        # facewin\n",
    "        # facesmile\n",
    "        # facedead\n",
    "        # print(time.time() - time0)\n",
    "        return 1\n",
    "    \n",
    "    def reset(self):\n",
    "        # Find the element by ID\n",
    "        element = self.driver.find_element_by_id(f\"face\")  # Replace \"element_id\" with the actual ID of your element\n",
    "\n",
    "        # Click on the element\n",
    "        element.click()\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamer = Minesweeper(driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dqn_model(input_size, output_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=input_size, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    model.compile(loss='mse', optimizer=Adam())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, gamma, epsilon, epsilon_decay, epsilon_min, model):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = []\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        if model is None:\n",
    "            self.model = create_dqn_model(state_size, action_size)\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        q_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = np.random.choice(len(self.memory), batch_size, replace=False)\n",
    "        for index in minibatch:\n",
    "            state, action, reward, next_state, done = self.memory[index]\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state, verbose = 0)[0])\n",
    "            target_f = self.model.predict(state, verbose=0)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_minesweeper(driver, model, runs):\n",
    "    # Initialize the environment\n",
    "    state_size = 16 * 30 * 10\n",
    "    action_size = 16 * 30\n",
    "    env = Minesweeper(driver)  # Replace with your Minesweeper environment\n",
    "\n",
    "    # Define hyperparameters\n",
    "    gamma = 0.95  # Discount factor\n",
    "    epsilon = 1.0  # Exploration rate\n",
    "    epsilon_decay = 0.995\n",
    "    epsilon_min = 0.01\n",
    "    batch_size = 32\n",
    "    episodes = runs\n",
    "\n",
    "    # Create the DQN agent\n",
    "    agent = DQNAgent(state_size, action_size, gamma, epsilon, epsilon_decay, epsilon_min, model)\n",
    "\n",
    "    \n",
    "    # Create a tqdm progress bar\n",
    "    progress_bar = tqdm(range(episodes))\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        env.reset()\n",
    "        state = env.cell_state  # Replace with your function to get the current game state\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        done = False\n",
    "        score = 0\n",
    "\n",
    "        while not done:\n",
    "            action = np.zeros(480, dtype=np.int8)\n",
    "            action[agent.act(state)] = 1\n",
    "\n",
    "            next_state, reward, done, win, lose = env.update_action(action)  # Replace with your function to perform an action in the environment\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            # reward = \n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "        agent.replay(batch_size)\n",
    "        progress_bar.set_description(f\"Episode: {episode}, Score: {score}, Epsilon: {epsilon:.2f}\")\n",
    "        progress_bar.update()\n",
    "        # if episode % 10 == 0:\n",
    "        #     print(\"Episode: {}, Score: {}, Epsilon: {:.2f}\".format(episode, score, agent.epsilon))\n",
    "\n",
    "    # Save the trained model\n",
    "    agent.model.save(\"minesweeper_dqn_model.h5\")\n",
    "    return agent.model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode: 9, Score: -8, Epsilon: 1.00: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "model = train_minesweeper(driver, model, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0023581334"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# driver.quit()\n",
    "state = np.zeros((1,4800))\n",
    "state [0,0] = 1\n",
    "res = model.predict(state, verbose=0)\n",
    "print(np.unravel_index(np.argmax(res), (16,30)))\n",
    "res = np.reshape(res, (16,30))\n",
    "res[13,28]\n",
    "# res.max()\n",
    "# res.flatten()\n",
    "# print(np.unravel_index(np.argmax(res), (16,30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
